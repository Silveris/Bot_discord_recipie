{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# binging scraper\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "from selenium import webdriver\n",
    "import dont_add"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# base recipe page scraper\n",
    "# geiing the urls of all the recipies\n",
    "\n",
    "# gets html from binging recipe page using a chrome browser\n",
    "# makes soup using the html\n",
    "url = 'https://www.bingingwithbabish.com/recipes'\n",
    "driver = webdriver.Chrome('chromedriver.exe')\n",
    "driver.get(url)\n",
    "soup = BeautifulSoup(driver.page_source, 'html.parser')\n",
    "driver.quit()\n",
    "\n",
    "# using the soup to get the urls list\n",
    "recipe_url_raw_info_soup = soup.find('div', class_='site-wrapper').find('div', class_='recipe-row').find_all('div', class_='recipe-col')\n",
    "recipe_urls = []\n",
    "\n",
    "# loops through and appends the urls to a list\n",
    "for recipe in recipe_url_raw_info_soup:\n",
    "    recipe_url = recipe.a['href']\n",
    "    recipe_urls.append(recipe_url)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# gets the recipe info from the recipe specific website\n",
    "# this will be in a for loop\n",
    "# that will loop through the url list\n",
    "\n",
    "\n",
    "url_base = 'https://www.bingingwithbabish.com'\n",
    "test_recipie_end_url = recipe_urls[1]\n",
    "url = url_base + test_recipie_end_url\n",
    "driver = webdriver.Chrome('chromedriver.exe')\n",
    "driver.get(test_url)\n",
    "test_soup = BeautifulSoup(driver.page_source, 'html.parser')\n",
    "driver.quit()\n",
    "\n",
    "# the bits we want\n",
    "recipe_title = test_soup.find('div', class_='site-wrapper').find('div', class_='page-title-wrapper').text.replace('\\n', '').strip()\n",
    "recipe_description = test_soup.find('div', class_='site-wrapper').find('div', class_='entry-content').h2.text\n",
    "ingredents_list_html = test_soup.find('div', class_='site-wrapper').find('div', class_='entry-content').ul.find_all('li')\n",
    "instructions_list_html = test_soup.find('div', class_='site-wrapper').find('div', class_='entry-content').ol.find_all('li')\n",
    "\n",
    "# gets the specific ingredents in the format we want\n",
    "ingredents = []\n",
    "for item in ingredents_list_html:\n",
    "    ingredents.append(item.text.replace('\\xa0', ''))\n",
    "\n",
    "# gets the specific steps in the format we want while indexing them\n",
    "steps = []\n",
    "i = 1\n",
    "for step in instructions_list_html:\n",
    "    trimmed = step.text.replace('\\xa0', '')\n",
    "    instruction = f'{i}. {trimmed}'\n",
    "    steps.append(instruction)\n",
    "    i += 1\n",
    "\n",
    "recipe = {\n",
    "    'Title' : recipe_title\n",
    "    ,'Author' : 'Babish'\n",
    "    ,'Url' : url\n",
    "    ,'Description' : recipe_description\n",
    "    ,'Ingredents' : ingredents\n",
    "    ,'Steps' : steps\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the for loop that gets all the data from the websites and adds the dicts into a list\n",
    "\n",
    "list_of_recipes = []\n",
    "url_base = 'https://www.bingingwithbabish.com'\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "for url_end in recipe_urls:\n",
    "    # makes the target url\n",
    "    url = url_base + url_end\n",
    "    print(f'getting html from {url}')\n",
    "    \n",
    "    # opens the browser to get the html\n",
    "    driver = webdriver.Chrome('chromedriver.exe')\n",
    "    driver.get(url)\n",
    "    soup = BeautifulSoup(driver.page_source, 'html.parser')\n",
    "    driver.quit()\n",
    "    \n",
    "    # the bits we want\n",
    "    recipe_title = soup.find('div', class_='site-wrapper').find('div', class_='page-title-wrapper').text.replace('\\n', '').strip()\n",
    "    recipe_description = soup.find('div', class_='site-wrapper').find('div', class_='entry-content').h2.text\n",
    "    ingredents_list_html = soup.find('div', class_='site-wrapper').find('div', class_='entry-content').ul.find_all('li')\n",
    "    instructions_list_html = soup.find('div', class_='site-wrapper').find('div', class_='entry-content').ol.find_all('li')\n",
    "\n",
    "    # gets the specific ingredents in the format we want\n",
    "    ingredents = []\n",
    "    for item in ingredents_list_html:\n",
    "        ingredents.append(item.text.replace('\\xa0', ''))\n",
    "\n",
    "    # gets the specific steps in the format we want while indexing them\n",
    "    steps = []\n",
    "    i = 1\n",
    "    for step in instructions_list_html:\n",
    "        trimmed = step.text.replace('\\xa0', '')\n",
    "        instruction = f'{i}. {trimmed}'\n",
    "        steps.append(instruction)\n",
    "        i += 1\n",
    "    \n",
    "    # loads the recipe dict\n",
    "    recipe = {\n",
    "        'Title' : recipe_title\n",
    "        ,'Author' : 'Babish'\n",
    "        ,'Url' : url\n",
    "        ,'Description' : recipe_description\n",
    "        ,'Ingredents' : ingredents\n",
    "        ,'Steps' : steps\n",
    "    }\n",
    "    \n",
    "    list_of_recipes.append(recipe)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# recipe = {\n",
    "#     'Title' : recipe_title\n",
    "#     ,'Author' : 'Babish'\n",
    "#     ,'Url' : url\n",
    "#     ,'Description' : recipe_description\n",
    "#     ,'Ingredents' : ingredents\n",
    "#     ,'Steps' : steps\n",
    "# }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# recipe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
